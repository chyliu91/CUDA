## 数组规约

### 仅使用全局内存
对于数组归约的并行计算问题，我们要从一个数组出发，最终得到一个数。所以，必须使用某种选代方案。假如数组元素个数是2的整数次方（我们稍后会去掉这个假设），我们可以将数组后半部分的各个元素与前半部分对应的数组元素相加。如果重复此过程，最后得到的第一个数组元素就是最初的数组中各个元素的和。这就是所谓的折半归约（binary reduction）法。

```
void __global__ reduce(double *d_x, int N)
{
    int n = blockDim.x * blockIdx.x + threadIdx.x;
    for (int offset = N / 2; offset > 0; offset /= 2)
    {
        if (n < offset)
        {
            d_x[n] += d_x[n + offset];
        }
    }
}
```

要保证核函数中语句的执行顺序与出现顺序一致，就必须使用某种同步机制。在CUDA中，提供了一个同步函数 `__syncthreads()`。该函数只能用在核函数中，并且不带任何参数:
```
__syncthreads();
```
该函数可保证一个线程块中的所有线程（或者说所有线程束）在执行该语句后面的语句之前都完全执行了该语句前面的语句。然而，该函数只是针对同一个线程块中的线程的，不同线程块中线程的执行次序依然是不确定的。

既然函数 `__syncthreads()` 能够同步单个线程块中的线程，那么我们就利用该功能让每个线程块对其中的数组元素进行归约。

```
void __global__ reduce_global(double *d_x, double *d_y)
{
    const int tid = threadIdx.x;
    double *x = d_x + blockDim.x * blockIdx.x;

    for (int offset = blockDim.x >> 1; offset > 0; offset >>= 1)
    {
        if (tid < offset)
        {
            x[tid] += x[tid + offset];
        }
        __syncthreads();
    }

    if (tid == 0)
    {
        d_y[blockIdx.x] = x[0];
    }
}
```

`double *x = d_x + blockDim.x * blockIdx.x;` 也可以写成 `double *x = &d_x[blockDim.x * blockIdx.x];`，这样定义的 `x` 在不同的线程块中指向全局内存中不同的地址，使得我们可以在不同的线程块中对数组 `d_x` 中不同的部分进行归约。具体地说，每一个线程块处理 `blockDim.x` 个数据。

`__syncthreads();` 保证了同一个线程块内的线程按照代码出现的顺序执行指令。至于两个不同线程块中的线程，则不一定按照代码出现的顺序执行指令，但这不影响程序的正确性。这是因为，在该核函数中，每个线程块都处理不同的数据，相互之间没有依赖。总结起来就是说，一个线程块内的线程需要合作，所以需要同步；两个线程块之间不需要合作，所以不需要同步。

该核函数仅仅将一个长度为 `10^8`的数组d_x归约到一个长度为 `10^8/128`的数组d_y。为了计算整个数组元素的和，我们将数组 `d_y` 从设备复制到主机，并在主机继续对数组 `d_y` 归约，得到最终的结果。这样做不是很高效，但我们暂时先这样做。


### 使用共享内存

在上面的核函数中，对全局内存的访问是很频繁的。全局内存的访问速度是所有内存中最低的，应该尽量减少对它的使用。所有设备内存中，寄存器是最高效的，但在需要线程合作的问题中，用仅对单个线程可见的寄存器是不够的。我们需要使用对整个线程块可见的共享内存。

在核函数中，要将一个变量定义为共享内存变量，就要在定义语句中加上一个限定符 `__shared__`。一般情况下，我们需要的是一个长度等于线程块大小的数组。在当前问题中，我们可以定义如下共享内存数组变量：
```
__shared__ double s_y[128];
```
如果没有限定符 `__shared__`，该语句将极有可能定义一个长度为 128 的局部数组。在一个核函数中定义一个共享内存变量，就相当于在每一个线程块中有了一个该变量的副本。每个副本都不一样，虽然它们共用一个变量名。核函数中对共享内存变量的操作都是同时作用在所有的副本上的。

```
void __global__ reduce_shared(double *d_x, double *d_y)
{
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int n = bid * blockDim.x + tid;
    __shared__ double s_y[128];
    s_y[tid] = (n < N) ? d_x[n] : 0.0;
    __syncthreads();

    for (int offset = blockDim.x >> 1; offset > 0; offset >>= 1)
    {
        if (tid < offset)
        {
            s_y[tid] += s_y[tid + offset];
        }
        __syncthreads();
    }

    if (tid == 0)
    {
        d_y[bid] = s_y[0];
    }
}
```

`s_y[tid] = (n < N) ? d_x[n] : 0.0;` 将全局内存中的数据复制到共享内存中。这里用到了前面说过的共享内存的特征：每个线程块都有一个共享内存变量的副本。其功能展开为：

- 当 `bid` 等于 `0` 时，将全局内存中第 `0` 到 `blockDim.x-1` 个数组元素复制给第 `0` 个线程块的共享内存变量副本。
- 当 `bid` 等于 `1` 时，将全局内存中 `blockDim.x` 到 `2*blockDim.x-1` 个数组元素复制给第 `1` 个线程块的共享内存变量副本。
- 因为这里有 `n < N` 的判断，所以该函数能够处理N不是线程块大小的整数倍的情形。此时，最后一个线程块中与条件 `n >= N` 对应的共享内存数组元素将被赋值为 `0`，不对归约（求和）的结果产生影响。

因为共享内存变量的生命周期仅仅在核函数内，所以必须在核函数结束之前将共享内存中的某些结果保存到全局内存，`if (tid == 0)` 可保证其中的语句在一个线程块中仅被执行一次。该语句的作用可以展开如下：

- 当 `bid` 等于 `0` 时，将第 `0` 个线程块中的 `s_y[0]` 副本复制给 `d_y[0]`；
- 当 `bid` 等于 `1` 时，将第 `1` 个线程块中的 `s_y[0]` 副本复制给 `d_y[1]`；
- 以此类推。


















